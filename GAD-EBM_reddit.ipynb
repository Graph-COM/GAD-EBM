{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065f66a4-5f68-4e14-acc7-0aa91959aa75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bcddab-f939-4f06-9009-da4a425cde65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy206/.conda/envs/cent7/2020.11-py38/NWRGAE/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import torch\n",
    "import scipy\n",
    "import random\n",
    "import pdb\n",
    "import copy\n",
    "import os\n",
    "import argparse\n",
    "    `\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv,GINConv,SAGEConv,GATConv,PNAConv, GraphSAGE\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from pygod.utils import load_data\n",
    "from pygod.metrics import eval_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc66f2b-ba3a-46b4-9b1e-4ae84087280f",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1b89a7-31e7-462b-b118-b961675b58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_random_edge(input_adj, perturb_percent=0.2, drop_edge = True, add_edge = True, self_loop = True):\n",
    "\n",
    "    aug_adj = copy.deepcopy(input_adj)\n",
    "    nb_nodes = input_adj.shape[0]\n",
    "    edge_index = (input_adj>0).nonzero().t()\n",
    "    \n",
    "    edge_dict = {}\n",
    "    for i in range(nb_nodes):\n",
    "        edge_dict[i] = set()\n",
    "    \n",
    "    for edge in edge_index:\n",
    "        i,j = edge[0],edge[1]\n",
    "        i = i.item()\n",
    "        j = j.item()\n",
    "        edge_dict[i].add(j)\n",
    "        edge_dict[j].add(i)\n",
    "    \n",
    "    if drop_edge: \n",
    "        for i in range(nb_nodes):\n",
    "            d = len(edge_dict[i])\n",
    "            node_list = list(edge_dict[i])\n",
    "            num_edge_to_drop = int(d * perturb_percent)\n",
    "\n",
    "            sampled_nodes = random.sample(node_list, num_edge_to_drop)\n",
    "\n",
    "            for j in sampled_nodes:\n",
    "                aug_adj[i][j] = 0\n",
    "                aug_adj[j][i] = 0\n",
    "\n",
    "            \n",
    "    node_list = [i for i in range(nb_nodes)]\n",
    "    # num_edge_to_add = int(nb_nodes * perturb_percent)\n",
    "    \n",
    "    add_list = []\n",
    "    for i in range(nb_nodes):\n",
    "        d = len(edge_dict[i])\n",
    "        num_edge_to_add = int(d * perturb_percent)\n",
    "        sampled_nodes = random.sample(node_list, num_edge_to_add)\n",
    "        for j in sampled_nodes:\n",
    "            add_list.append((i,j))\n",
    "            \n",
    "    if add_edge:\n",
    "        for i in add_list:\n",
    "            aug_adj[i[0]][i[1]] = 1\n",
    "            aug_adj[i[1]][i[0]] = 1\n",
    "    \n",
    "    if self_loop: \n",
    "        for i in range(nb_nodes):\n",
    "            aug_adj[i][i] = 1\n",
    "            aug_adj[i][i] = 1\n",
    "    \n",
    "    \n",
    "    return aug_adj\n",
    "\n",
    "\n",
    "def _aug_random_edge(nb_nodes, edge_index, perturb_percent=0.2, drop_edge = True, add_edge = True, self_loop = True, use_avg_deg = True):\n",
    "\n",
    "    \n",
    "    total_edges = edge_index.shape[1]\n",
    "    avg_degree = int(total_edges/nb_nodes)\n",
    "    \n",
    "    \n",
    "    edge_dict = {}\n",
    "    for i in range(nb_nodes):\n",
    "        edge_dict[i] = set()\n",
    "    \n",
    "    for edge in edge_index:\n",
    "        i,j = edge[0],edge[1]\n",
    "        i = i.item()\n",
    "        j = j.item()\n",
    "        edge_dict[i].add(j)\n",
    "        edge_dict[j].add(i)\n",
    "    \n",
    "    if drop_edge: \n",
    "        for i in range(nb_nodes):\n",
    "            \n",
    "            d = len(edge_dict[i])\n",
    "            if use_avg_deg:\n",
    "                num_edge_to_drop = avg_degree\n",
    "            else:\n",
    "                num_edge_to_drop = int(d * perturb_percent)\n",
    "\n",
    "            node_list = list(edge_dict[i])\n",
    "            num_edge_to_drop = min(num_edge_to_drop, d)\n",
    "            sampled_nodes = random.sample(node_list, num_edge_to_drop)\n",
    "\n",
    "            for j in sampled_nodes:\n",
    "                edge_dict[i].discard(j)\n",
    "                edge_dict[j].discard(i)\n",
    "            \n",
    "    node_list = [i for i in range(nb_nodes)]\n",
    "    \n",
    "    add_list = []\n",
    "    for i in range(nb_nodes):\n",
    "        \n",
    "        if use_avg_deg:\n",
    "            num_edge_to_add =  avg_degree\n",
    "        else:\n",
    "            d = len(edge_dict[i])\n",
    "            num_edge_to_add = int(d * perturb_percent)\n",
    "        \n",
    "        sampled_nodes = random.sample(node_list, num_edge_to_add)\n",
    "        for j in sampled_nodes:\n",
    "            add_list.append((i,j))\n",
    "            \n",
    "    if add_edge:\n",
    "        for edge in add_list:\n",
    "            u = edge[0]\n",
    "            v = edge[1]\n",
    "            \n",
    "            edge_dict[u].add(v)\n",
    "            edge_dict[v].add(u)\n",
    "    \n",
    "    if self_loop: \n",
    "        for i in range(nb_nodes):\n",
    "            edge_dict[i].add(i)\n",
    "            \n",
    "    updated_edges = set()\n",
    "    for i in range(nb_nodes):\n",
    "        for j in edge_dict[i]:\n",
    "            updated_edges.add((i,j))\n",
    "            updated_edges.add((j,i))\n",
    "    \n",
    "    row = []\n",
    "    col = []\n",
    "    for edge in updated_edges:\n",
    "        u = edge[0]\n",
    "        v = edge[1]\n",
    "        row.append(u)\n",
    "        col.append(v)\n",
    "    \n",
    "    aug_edge_index = [row,col]\n",
    "    aug_edge_index = torch.tensor(aug_edge_index)\n",
    "    \n",
    "    return aug_edge_index\n",
    "\n",
    "\n",
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
    "    features = features.squeeze()\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return features\n",
    "    # return features, sparse_to_tuple(features)\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0866d6-d178-4377-93a3-6d6cc8de664a",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bd95b9-2f6a-4331-bb74-bd175d2a8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.linear_or_not = True  # default is linear model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(\"number of layers should be positive!\")\n",
    "        elif num_layers == 1:\n",
    "            # Linear model\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "        else:\n",
    "            # Multi-layer model\n",
    "            self.linear_or_not = False\n",
    "            self.linears = torch.nn.ModuleList()\n",
    "            self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "            self.linears.append(nn.Linear(input_dim, hidden_dim))\n",
    "            for layer in range(num_layers - 2):\n",
    "                self.linears.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.linears.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "            for layer in range(num_layers - 1):\n",
    "                self.batch_norms.append(nn.BatchNorm1d((hidden_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.linear_or_not:\n",
    "            # If linear model\n",
    "            return self.linear(x)\n",
    "        else:\n",
    "            # If MLP\n",
    "            h = x\n",
    "            for layer in range(self.num_layers - 1):\n",
    "                h = self.linears[layer](h)\n",
    "                \n",
    "                if len(h.shape) > 2:\n",
    "                    h = torch.transpose(h, 0, 1)\n",
    "                    h = torch.transpose(h, 1, 2)\n",
    "                    \n",
    "                \n",
    "                if len(h.shape) > 2:\n",
    "                    h = torch.transpose(h, 1, 2)\n",
    "                    h = torch.transpose(h, 0, 1)\n",
    "\n",
    "                h = F.relu(h)\n",
    "                \n",
    "            return self.linears[self.num_layers - 1](h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64572324-7c46-4363-b541-8c9194e22e6e",
   "metadata": {},
   "source": [
    "# GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7d67c6-672e-428d-91d5-dd0dc6d82fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, GNN_name = \"GCN\"):\n",
    "    \n",
    "        super(GNN, self).__init__()    \n",
    "        \n",
    "        self.mlp0 = MLP(3, in_dim, out_dim, out_dim)\n",
    "        \n",
    "        if GNN_name == \"GIN\":\n",
    "            self.linear1 = MLP(4, out_dim, out_dim, out_dim)\n",
    "            self.graphconv1 = GINConv(self.linear1)\n",
    "        elif GNN_name == \"GCN\":\n",
    "            self.graphconv1 = GCNConv(out_dim, out_dim, aggr='mean')\n",
    "        elif GNN_name == \"GAT\":\n",
    "            self.graphconv1 = GATConv(out_dim, out_dim, aggr='mean')\n",
    "        elif GNN_name == \"SAGE\":\n",
    "            self.graphconv1 = SAGEConv(out_dim, out_dim, aggr='mean')\n",
    "            \n",
    "        self.mlp1 = nn.Linear(out_dim,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        h0 = self.mlp0(x)\n",
    "        h1 = self.graphconv1(h0,edge_index)\n",
    "        h2 = self.mlp1(h1)\n",
    "        h2 = self.relu(h2)\n",
    "        p = torch.exp(h2)\n",
    "        \n",
    "        return p\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaafc73-dc35-4c78-80eb-779cb790fa14",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ceafb622-a294-4cd9-b76a-dd8ae8539be1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Namespace(GNN_name='GCN', add_edge=False, dataset='reddit', drop_edge=True, f='/home/roy206/.local/share/jupyter/runtime/kernel-9181bf92-95f3-4d04-94c1-17f217717299.json', gpu=0, hidden_dim=16, l2_coef=10.0, lr=0.001, nb_epochs=100, num_neigh=1, perturb_percent=0.05, preprocess_feat=True, save_name='try.pkl', seed=10, self_loop=True, use_avg_deg=False)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Loss:  0.7074172496795654 AUC Score:  58.41796639792002\n",
      "Loss:  0.6891579627990723 AUC Score:  58.41653826320291\n",
      "Loss:  0.6711058616638184 AUC Score:  58.41661545967411\n",
      "Loss:  0.6532433032989502 AUC Score:  58.400417066801715\n",
      "Loss:  0.6314446926116943 AUC Score:  58.16199576551624\n",
      "Loss:  0.6078312397003174 AUC Score:  58.14851211521419\n",
      "Loss:  0.5836055278778076 AUC Score:  58.15265499250165\n",
      "Loss:  0.559135913848877 AUC Score:  58.15003031248103\n",
      "Loss:  0.5347127914428711 AUC Score:  58.15139411680546\n",
      "Loss:  0.5104522705078125 AUC Score:  58.15187016171117\n",
      "Loss:  0.48641252517700195 AUC Score:  58.1518444295541\n",
      "Loss:  0.46265101432800293 AUC Score:  58.151883027789694\n",
      "Loss:  0.4391911029815674 AUC Score:  58.15198595641796\n",
      "Loss:  0.41605138778686523 AUC Score:  58.15199882249649\n",
      "Loss:  0.39324069023132324 AUC Score:  58.15214034936036\n",
      "Loss:  0.37076425552368164 AUC Score:  58.15211461720329\n",
      "Loss:  0.34862327575683594 AUC Score:  58.15217894759594\n",
      "Loss:  0.32681918144226074 AUC Score:  58.15219181367448\n",
      "Loss:  0.30535149574279785 AUC Score:  58.15220467975302\n",
      "Loss:  0.28421545028686523 AUC Score:  58.152217545831554\n",
      "Loss:  0.263416051864624 AUC Score:  58.15199882249649\n",
      "Loss:  0.24295496940612793 AUC Score:  58.15196022426089\n",
      "Loss:  0.22283196449279785 AUC Score:  58.151921626025306\n",
      "Loss:  0.2030467987060547 AUC Score:  58.151998822496495\n",
      "Loss:  0.18359923362731934 AUC Score:  58.152127483281824\n",
      "Loss:  0.1645045280456543 AUC Score:  58.1544948417318\n",
      "Loss:  0.14576506614685059 AUC Score:  58.15457203820299\n",
      "Loss:  0.12735724449157715 AUC Score:  58.15459777036005\n",
      "Loss:  0.10927867889404297 AUC Score:  58.15475216330243\n",
      "Loss:  0.09152579307556152 AUC Score:  58.1540573950617\n",
      "Loss:  0.07409548759460449 AUC Score:  58.15399306466902\n",
      "Loss:  0.05698895454406738 AUC Score:  58.15389013604077\n",
      "Loss:  0.04020428657531738 AUC Score:  58.153838671726646\n",
      "Loss:  0.02373957633972168 AUC Score:  58.15378720741251\n",
      "Loss:  0.007591724395751953 AUC Score:  58.1538644038837\n",
      "Loss:  -0.00823974609375 AUC Score:  58.153761475255436\n",
      "Loss:  -0.023758411407470703 AUC Score:  58.153825805648104\n",
      "Loss:  -0.03896737098693848 AUC Score:  58.153838671726646\n",
      "Loss:  -0.05386829376220703 AUC Score:  58.15385153780517\n",
      "Loss:  -0.06846499443054199 AUC Score:  58.153980198590496\n",
      "Loss:  -0.07957720756530762 AUC Score:  58.15395446643343\n",
      "Loss:  -0.06551647186279297 AUC Score:  58.15392873427636\n",
      "Loss:  -0.053452491760253906 AUC Score:  58.15396733251197\n",
      "Loss:  -0.04297447204589844 AUC Score:  58.154005930747566\n",
      "Loss:  -0.03356599807739258 AUC Score:  58.15364568054865\n",
      "Loss:  -0.024967670440673828 AUC Score:  58.1537100109413\n",
      "Loss:  -0.017241477966308594 AUC Score:  58.15372287701985\n",
      "Loss:  -0.010239124298095703 AUC Score:  58.15367141270571\n",
      "Loss:  -0.003834247589111328 AUC Score:  58.15369714486278\n",
      "Loss:  0.0020864009857177734 AUC Score:  58.1537100109413\n",
      "Loss:  0.0076215267181396484 AUC Score:  58.153825805648104\n",
      "Loss:  0.012857437133789062 AUC Score:  58.15368427878425\n",
      "Loss:  0.017871856689453125 AUC Score:  58.153761475255436\n",
      "Loss:  0.022731304168701172 AUC Score:  58.15377434133397\n",
      "Loss:  0.0274960994720459 AUC Score:  58.153825805648104\n",
      "Loss:  0.03222060203552246 AUC Score:  58.15450770781033\n",
      "Loss:  0.03696084022521973 AUC Score:  58.15477789545952\n",
      "Loss:  0.04176926612854004 AUC Score:  58.1550094848731\n",
      "Loss:  0.04664421081542969 AUC Score:  58.15506094918723\n",
      "Loss:  0.051595449447631836 AUC Score:  58.15493228840191\n",
      "Loss:  0.056636810302734375 AUC Score:  58.15503521703016\n",
      "Loss:  0.06177878379821777 AUC Score:  58.15491942232337\n",
      "Loss:  0.06702947616577148 AUC Score:  58.15507381526576\n",
      "Loss:  0.07239222526550293 AUC Score:  58.15503521703016\n",
      "Loss:  0.07786893844604492 AUC Score:  58.155022350951626\n",
      "Loss:  0.08345627784729004 AUC Score:  58.1549708866375\n",
      "Loss:  0.08915352821350098 AUC Score:  58.155086681344294\n",
      "Loss:  0.0949556827545166 AUC Score:  58.155022350951626\n",
      "Loss:  0.10085725784301758 AUC Score:  58.154958020558965\n",
      "Loss:  0.10685253143310547 AUC Score:  58.15502235095163\n",
      "Loss:  0.11293411254882812 AUC Score:  58.15500948487309\n",
      "Loss:  0.11909675598144531 AUC Score:  58.155086681344294\n",
      "Loss:  0.1253349781036377 AUC Score:  58.15509954742283\n",
      "Loss:  0.13164591789245605 AUC Score:  58.1549708866375\n",
      "Loss:  0.13802528381347656 AUC Score:  58.1550094848731\n",
      "Loss:  0.1444697380065918 AUC Score:  58.15503521703016\n",
      "Loss:  0.15096569061279297 AUC Score:  58.15500948487309\n",
      "Loss:  0.15747690200805664 AUC Score:  58.154958020558965\n",
      "Loss:  0.16400861740112305 AUC Score:  58.154867958009234\n",
      "Loss:  0.1705646514892578 AUC Score:  58.15494515448043\n",
      "Loss:  0.17714858055114746 AUC Score:  58.15490655624483\n",
      "Loss:  0.1837632656097412 AUC Score:  58.154958020558965\n",
      "Loss:  0.19041132926940918 AUC Score:  58.154958020558965\n",
      "Loss:  0.19709324836730957 AUC Score:  58.15516387781548\n",
      "Loss:  0.2038123607635498 AUC Score:  58.155048083108696\n",
      "Loss:  0.2105698585510254 AUC Score:  58.1550094848731\n",
      "Loss:  0.21736574172973633 AUC Score:  58.1549708866375\n",
      "Loss:  0.224198579788208 AUC Score:  58.154867958009234\n",
      "Loss:  0.23106908798217773 AUC Score:  58.15475216330245\n",
      "Loss:  0.2379767894744873 AUC Score:  58.154867958009234\n",
      "Loss:  0.24492263793945312 AUC Score:  58.15491942232337\n",
      "Loss:  0.2519054412841797 AUC Score:  58.15484222585218\n",
      "Loss:  0.2589266300201416 AUC Score:  58.15481649369511\n",
      "Loss:  0.2659912109375 AUC Score:  58.15461063643858\n",
      "Loss:  0.27309298515319824 AUC Score:  58.15480362761658\n",
      "Loss:  0.2802314758300781 AUC Score:  58.154880824087776\n",
      "Loss:  0.28738999366760254 AUC Score:  58.15491942232338\n",
      "Loss:  0.29458022117614746 AUC Score:  58.154996618794556\n",
      "Loss:  0.30183982849121094 AUC Score:  58.154867958009234\n",
      "Loss:  0.3091244697570801 AUC Score:  58.15502235095163\n",
      "Maximum AUC:  58.41796639792002\n",
      "Required Time:  1.5822398662567139\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "parser = argparse.ArgumentParser(\"GAD-EBM: Graph Anomaly Detection via Energy-based Model\")\n",
    "\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('--dataset',          type=str,           default=\"reddit\",         help='dataset name')\n",
    "parser.add_argument('--perturb_percent',  type=float,         default=0.05,             help='perturb percent')\n",
    "parser.add_argument('--seed',             type=int,           default=10,               help='seed')\n",
    "parser.add_argument('--nb_epochs',        type=int,           default=100,              help='total epochs')\n",
    "parser.add_argument('--hidden_dim',       type=int,           default=16,               help='hidden dimension')\n",
    "parser.add_argument('--lr',               type=float,         default=0.001,            help='learning rate')\n",
    "parser.add_argument('--l2_coef',          type=float,         default=10.0,             help='regularization coefficeint')\n",
    "parser.add_argument('--gpu',              type=int,           default=0,                help='gpu')\n",
    "parser.add_argument('--save_name',        type=str,           default='try.pkl',        help='save ckpt name')\n",
    "parser.add_argument('--drop_edge',        type=bool,          default=True,             help='drop edge flag to produce state space neighbor')\n",
    "parser.add_argument('--add_edge',         type=bool,          default=False,            help='add edge flag to produce state space neighbor')\n",
    "parser.add_argument('--self_loop',        type=bool,          default=True,             help='self loop in state space neighbor')\n",
    "parser.add_argument('--preprocess_feat',  type=bool,          default=True,             help='preprocess feature flag')\n",
    "parser.add_argument('--use_avg_deg',      type=bool,          default=False,            help='use avg_deg to add/drop edge in state space neighbor')\n",
    "parser.add_argument('--GNN_name',         type=str,           default=\"GCN\",            help='gnn encoder')\n",
    "parser.add_argument('--num_neigh',        type=int,           default=1,                help='state space graph number of neighbors')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('-' * 100)\n",
    "print(args)\n",
    "print('-' * 100)\n",
    "\n",
    "dataset_str = args.dataset\n",
    "perturb_percent = args.perturb_percent\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) \n",
    "seed = args.seed\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "\n",
    "nb_epochs = args.nb_epochs\n",
    "lr = args.lr\n",
    "l2_coef = args.l2_coef\n",
    "hidden_dim = args.hidden_dim\n",
    "k = args.num_neigh\n",
    "\n",
    "\n",
    "\n",
    "data = load_data(dataset_str)\n",
    "edge_index = data.edge_index\n",
    "\n",
    "\n",
    "adj = to_dense_adj(edge_index).squeeze()\n",
    "features = data.x\n",
    "labels = data.y\n",
    "y = labels.bool()\n",
    "\n",
    "anomaly_nodes = np.nonzero(y)\n",
    "\n",
    "nb_nodes = features.shape[0]  # total node\n",
    "input_dim = features.shape[1]   # total features\n",
    "\n",
    "\n",
    "\n",
    "model = GNN(input_dim, hidden_dim, args.GNN_name)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_coef)\n",
    "\n",
    "\n",
    "if args.preprocess_feat:\n",
    "    features = preprocess_features(features)\n",
    "\n",
    "    \n",
    "\n",
    "st = time.time()\n",
    "mx_auc = 0\n",
    "\n",
    "aug_edge_indexes = []\n",
    "\n",
    "for i in range(k):\n",
    "    aug_edge_index = _aug_random_edge(nb_nodes,edge_index, perturb_percent=perturb_percent,drop_edge=args.drop_edge,\n",
    "                                  add_edge=args.add_edge,self_loop=args.self_loop, use_avg_deg = args.use_avg_deg) # add/drop perturb percentage of edges\n",
    "    \n",
    "    \n",
    "    aug_edge_index = aug_edge_index.to(device)\n",
    "    \n",
    "    aug_edge_indexes.append(aug_edge_index)\n",
    "    \n",
    "    \n",
    "model = model.to(device)\n",
    "features = torch.FloatTensor(features[np.newaxis])\n",
    "features = features.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "\n",
    "losses = []\n",
    "    \n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "    model.train()\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    p_data = model(features, edge_index)\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        \n",
    "        aug_edge_index = aug_edge_indexes[i]\n",
    "        \n",
    "        shuf_fts = features\n",
    "        idx = np.random.permutation(nb_nodes)\n",
    "        shuf_fts = features[:, idx, :]\n",
    "        \n",
    "        \n",
    "        p_neigh = model(shuf_fts, aug_edge_index)\n",
    "    \n",
    "        c_theta_j1 = p_neigh/p_data\n",
    "        c_theta_j2 = p_data/p_neigh\n",
    "            \n",
    "        j1 = (c_theta_j1**2 + 2 * c_theta_j1).mean()\n",
    "        j2 = (2 * c_theta_j2).mean()\n",
    "        \n",
    "        \n",
    "        \n",
    "        neigh_loss = j1 - j2\n",
    "        neigh_loss = neigh_loss.mean()\n",
    "        loss = loss + neigh_loss\n",
    "    \n",
    "    loss = loss / k\n",
    "    \n",
    "    losses.append(loss)\n",
    "    \n",
    "\n",
    "    \n",
    "    logits = p_data.squeeze().detach().cpu() \n",
    "    auc_score = eval_roc_auc(y.numpy(), logits.numpy()) * 100\n",
    "    \n",
    "    print(\"Loss: \", loss.item(), \"AUC Score: \", auc_score)\n",
    "    mx_auc = max(mx_auc, auc_score)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "en = time.time()\n",
    "\n",
    "\n",
    "print(\"Maximum AUC: \", mx_auc)\n",
    "print(\"Required Time: \", en-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb6826-d298-4b49-a056-ad55e52eb29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NWRGAE",
   "language": "python",
   "name": "nwrgae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
